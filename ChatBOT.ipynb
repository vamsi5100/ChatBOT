{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80635b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\guthu\\Desktop\\CHATBOT')\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b037d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e429f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "759b6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "patterns = []\n",
    "responses = {}\n",
    "for intent in data['intents']:\n",
    "    for sentence in intent['patterns']:\n",
    "        labels.append(intent['tag'].lower())\n",
    "        patterns.append(sentence)\n",
    "        responses[intent['tag'].lower()]=intent['responses']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b54653cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greeting': ['Hello, thanks for visiting',\n",
       "  'Good to see you again',\n",
       "  'Hi there, how can I help?'],\n",
       " 'goodbye': ['See you later, thanks for visiting',\n",
       "  'Have a nice day',\n",
       "  'Bye! Come back again soon.'],\n",
       " 'thanks': ['Happy to help!', 'Any time!', 'My pleasure'],\n",
       " 'hours': [\"We're open every day from 9AM to 9PM\",\n",
       "  'Our working hours are 9AM to 9PM every day'],\n",
       " 'location': ['We are on BH-5, LPU',\n",
       "  'Our company is situated in BH-5, LPU',\n",
       "  'We work from BH-5 LPU',\n",
       "  'Our location is BH-5 LPU'],\n",
       " 'payments': ['We accept VISA, Mastercard and AMEX',\n",
       "  'We accept most major credit cards'],\n",
       " 'services': ['We provide Web Penetration Testing,Android Penetration Testing,Docker Penetration Testing,Vulnerability Assessment,Cyber Crime investigation and many more services.']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445455a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7800e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes = sorted(list(set(labels)))\n",
    "len(Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40940dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels=[]  \n",
    "for label in Classes:\n",
    " bag = [] \n",
    " for sentence in labels:\n",
    "  T = [sentence.lower()]\n",
    "  if label in T:\n",
    "      bag.append(1)\n",
    "  else:\n",
    "      bag.append(0)\n",
    " Labels.append(bag)\n",
    "Labels = np.transpose(np.array(Labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a55f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714e8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "def text_preprocessing(responses):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    S=[]\n",
    "    W=[]\n",
    "    for sentence in responses:\n",
    "        x = re.sub('[^a-zA-Z]',' ',sentence)\n",
    "        x = x.lower()\n",
    "        words = word_tokenize(x)\n",
    "        L=[]\n",
    "        for word in words:\n",
    "         x = word                  #lemmatizer.lemmatize(word)\n",
    "         W.append(x)\n",
    "         L.append(x)\n",
    "        x = ' '.join(L)\n",
    "        S.append(x)\n",
    "        W = sorted(list(set(W)))\n",
    "    return (S,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e45339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text,words = text_preprocessing(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4519ffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b4f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(patterns,words):  \n",
    "  text_num=[]  \n",
    "  for sentence in patterns:\n",
    "    D = []\n",
    "    for i in range(len(words)):\n",
    "        D.append(0)    \n",
    "        H=D\n",
    "    T = sentence.lower()\n",
    "    T = word_tokenize(sentence)\n",
    "    for x in T:\n",
    "        for j in range(len(H)):\n",
    "            if words[j]==x:  \n",
    "                H[j]=1\n",
    "    text_num.append(H)\n",
    "  text_num = np.array(text_num)\n",
    "  return text_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "004462db",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_num = onehot(processed_text,words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b77bdbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b70a87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(text_num,Labels,test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e4acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 51)\n",
      "(9, 51)\n",
      "(21, 7)\n",
      "(9, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "012cc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Embedding\n",
    "from keras.optimizers  import Adam,SGD\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec8cbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(X_train.shape[1],)))\n",
    "    for i in range(hp.Int('num_layers', 2,10)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(Y_train.shape[1], activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bb92d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 09s]\n",
      "val_auc: 0.5751029253005981\n",
      "\n",
      "Best val_auc So Far: 0.9526748657226562\n",
      "Total elapsed time: 00h 12m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory=r'C:\\Users\\guthu\\Desktop\\CHATBOT\\hyperparameters',\n",
    "    project_name='Chatbot')\n",
    "\n",
    "tuner.search(X_train,Y_train, epochs=300,batch_size=512, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51b3afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d1173c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 51)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6656      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 96)                24672     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               12416     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 192)               12480     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 448)               86464     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 3143      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 187,111\n",
      "Trainable params: 187,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.build(input_shape=(X_train.shape[1],))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "927d3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('chatbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff3cad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Classes.pkl','wb') as h:\n",
    "    pickle.dump(Classes,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65756a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words.pkl','wb') as h:\n",
    "    pickle.dump(words,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab83a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('responses.pkl','wb') as h:\n",
    "    pickle.dump(responses,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2d7eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(X,model,Classes):  \n",
    "    p = model.predict(X)\n",
    "    C=[]\n",
    "    for i in range(len(p)):\n",
    "       index = np.argmax(p[i])\n",
    "       c = Classes[index]\n",
    "       C.append(c)\n",
    "    return C\n",
    "from numpy.linalg import norm\n",
    "def cosine_similarity(A,B):\n",
    "    x = norm(A, axis=1).reshape(-1,1)\n",
    "    cosine = np.dot(A,B)/(x*norm(B))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9cc10e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hours']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict(X_test[:1],best_model,Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2c5727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hours', 'services', 'payments', 'payments', 'location', 'thanks', 'greeting', 'hours', 'services']\n"
     ]
    }
   ],
   "source": [
    "C=[]\n",
    "for i in range(len(Y_test)):\n",
    "   index = np.argmax(Y_test[i])\n",
    "   c = Classes[index]\n",
    "   C.append(c)\n",
    "print(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
